<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="utf-8" />
  <title>DM2 Lab: Data Mining towards Decision Making</title>
  <!-- Favicon -->
  <link rel="shortcut icon" href="images/favicon.gif" />
  <!-- Standard reset, fonts and grids -->
  <link rel="stylesheet" type="text/css" href="styles/reset-fonts-grids.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <!-- styles for the whole website -->
  <link href="styles/styles.css" rel="stylesheet" type="text/css" />
  <!-- scripts -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="http://www.francois-petitjean.com/main.js" type="text/javascript"></script>
</head>

<body class="yui-skin-sam" id="yahoo-com">
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

  <div id="doc" class="yui-t1">
  <div id="hd">
    <div id="header"><a href="https://www.nd.edu/"><img id="nd-logo" src="images/logo_nd.png" alt="CSE@NotreDame" /></a></div>    
  </div>

  <h1>NSF III: Small: Intelligent Scientific Text Analytics with Knowledge-Augmented Abductive Reasoning</h1>

  <h2>Project Description (NSF IIS-2234058)</h2>
  
  <div>Scientists are producing vast numbers of research articles and patents every year to advance our understanding of our world and the universe. Meanwhile, they are making a great effort to build tools to boost their productivity. While these tools are able to process scientific text, they are not endowed with intelligence to think or write like scientists to help their work. Natural language generation systems may generate some new statements that are fluent to read and hard to distinguish from human-written texts. However, existing systems are not as intelligent or reliable as working with human research assistants due to lack of reasoning abilities about scientific innovation. This project aims to enable comparative reasoning in a novel intelligent system of scientific text analytics, which is missing in existing systems. Comparative reasoning establishes the importance of something by comparing it against something else. Comparative reasoning plays a central role in scientific innovation and can be categorized as abductive reasoning in the context of artificial intelligence. This project will design and develop novel text generation approaches for scientific abductive reasoning and intelligent scientific text analytics. Moreover, this research will support the professional development of a cohort of PhD, undergraduate, and high school students.</div>

  <br>

  <div>The technical aims of the project are divided into three thrusts. The first develops and compares natural language generation models based on a data-driven architecture and a novel architecture inspired and rooted in theories of abduction. These models will be evaluated on the tasks of comparative summarization and comparative argument generation in scientific domains. The second thrust designs retrieval-augmented approaches with heterogeneous knowledge sources such as tables, taxonomies, and knowledge graphs to improve the performance of scientific abductive reasoning models. Because retrieving and encoding every instance can be very time consuming, the third thrust builds knowledge memory networks that learns and manages distributed representations of scientific concepts and relations from the knowledge sources. They will accelerate the retrieval augmentation, when all the types of scientific source data are of large scale. Finally, these techniques will be integrated into a new artificial intelligence system that accurately generates explanatory sentences to automate comparative reasoning and assist scientific innovation.</div>

  <br>

  <div>We are grateful for NSF support to make this project possible!</div>

  <h2>Faculty</h2>

    <table>
    <td width="150" height="155">
        <img src="lab/images/meng.jpg" height="150" />
    </td>
    <td width="600">
        <div><a href="http://www.meng-jiang.com">Meng Jiang</a></div>
    </td>
    </table>

  <h2>Research Assistants</h2>

    <table>
    <td width="150" height="155">
        <img src="lab/images/mengxia.jpg" height="150" />
    </td>
    <td width="850">
        <div><a href="https://scholar.google.com.pr/citations?user=9d9qJt8AAAAJ">Mengxia Yu</a></div>
    </td>
    </table>

    <table>    
    <td width="150" height="155">
        <img src="lab/images/zhihan.jpg" height="150" />
    </td>
    <td width="850">
        <div><a href="http://ytyz1307zzh.github.io">Zhihan Zhang</a></div>
    </td>
    </table>

    <table>
    <td width="150" height="155">
        <img src="lab/images/wenhao.jpg" height="150" />
    </td>
    <td width="850">
        <div><a href="https://wyu97.github.io/">Wenhao Yu</a></div>
    </td>
    </table>
    
  <h2>Publications</h2>

  <ul>

    <li class="O"><a href="https://arxiv.org/abs/2503.15354">Optimizing Decomposition for Optimal Claim Verification</a>
    <i>Annual Meetings of the Association for Computational Linguistics (<b>ACL</b>)</i>, 2025.
    </li>
    
    <li class="O"><a href="#">Aligning Large Language Models with Implicit Preferences from User-Generated Content</a>
    <i>Annual Meetings of the Association for Computational Linguistics (<b>ACL</b>)</i>, 2025.
    </li>
    
    <li class="O"><a href="https://arxiv.org/abs/2410.14179">MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems</a>
    <i>Annual Conference of the North American Chapter of the Association for Computational Linguistics (<b>NAACL</b>)</i>, 2025.
    </li>

    <li class="O"><a href="https://arxiv.org/abs/2305.14010">IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions</a>
    <i>Conference on Empirical Methods in Natural Language Processing (<b>EMNLP</b>)</i>, 2023.
    </li>

    <li class="O"><a href="https://document-intelligence.github.io/DI-2022/files/di-2022_final_15.pdf">Scientific Comparative Argument Generation</a>
    <i>Third Document Intelligence Workshop (DI)</i> at
    <i>ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</i>, 2022.
    </li>

    <li class="O"><a href="https://aclanthology.org/2022.emnlp-main.43/">A Unified Encoder-Decoder Framework with Entity Memory</a>
    <i>Empirical Methods on Natural Language Processing (<b>EMNLP</b>)</i>, 2022.
    </li>

    <li class="O"><a href="https://aclanthology.org/2022.emnlp-main.294/">Retrieval Augmentation for Commonsense Reasoning: A Unified Approach</a>
    <i>Empirical Methods on Natural Language Processing (<b>EMNLP</b>)</i>, 2022.
    </li>

    <li class="O"><a href="https://aclanthology.org/2022.findings-acl.149/">Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts</a>
    Findings of <i>Annual Meeting of the Association for Computational Linguistics (<b>ACL</b>)</i>, 2022.
    </li>

  </ul>

  <br><br><br><br><br>
  <br><br><br><br><br>

    <table>
    <td width="100" height="100">
        <img src="images/nsf.jpg" width="100" />
    </td>
    <td width="100" height="100">
        <img src="images/ndengineering.png" width="100" />
    </td>
    </table>
    
  </div>

  <br><br><br><br><br>  

</body>

