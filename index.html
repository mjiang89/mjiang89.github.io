<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="utf-8" />
  <title>Meng Jiang - University of Notre Dame</title>
  <!-- Favicon -->
  <link rel="shortcut icon" href="images/favicon.gif" />
  <!-- Standard reset, fonts and grids -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="styles/reset-fonts-grids.css">
  <!-- styles for the whole website -->
  <link href="styles/styles.css" rel="stylesheet" type="text/css" />
</head>

<body class="yui-skin-sam" id="yahoo-com">
  <div id="doc" class="yui-t1">
  <div id="hd">
    <div id="header"><a href="https://www.nd.edu/"><img id="nd-logo" src="images/logo_nd.png" alt="CSE@NotreDame" /></a></div>
  </div>

  <!-- START: left column -->
  <div id="left-column">
  <!--#include virtual="left_column.html" -->
  <img id="meng-img" src="images/meng.jpg" alt="Meng Jiang" />
  <div id="graphgardenmainmenu" class="yuimenu">
    <div class="bd">
      <ul class="first-of-type">
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="lab.html"><b>DM2 Lab</b></a></li>
      <br>
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="index.html">Home</a></li>
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="pubs.html">Publications</a></li>
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="activities.html">Activities</a></li>
      <br>
      </ul>
    </div>
  </div>
  <br>
  </div>
  <!-- END: left column -->

  <!-- START: right column -->
  <div id="right-column">

    <div class="call-out-orange"><div style="font-size:36px; padding:13px 0px; font-family:Arial, Helvetica, sans-serif; font-weight:bold;";>Meng Jiang</div></div>

    <p>Hi! I am an Associate Professor and Frank M. Freimann Collegiate Professor of <a href="http://cse.nd.edu/">Computer Science and Engineering</a> at the <a href="https://www.nd.edu/">University of Notre Dame</a>. I'm appointed as a <a href="https://lucyinstitute.nd.edu/people/affiliates/">Lucy Family Institute Fellow</a> as well as the Program Chair of <a href="https://ethics.nd.edu/labs-and-centers/notre-dame-ibm-technology-ethics-lab/">ND-IBM Tech Ethics Lab</a>. I am also an <a href="https://www.amazon.science/scholars">Amazon Scholar</a>. My research fields are AI and Data Science. I'm interested in <i style="color:green">text and graph data</i> for applications such as <a href="https://arxiv.org/abs/2303.10108">material discovery</a>, <a href="https://arxiv.org/abs/2312.11518">recommender system</a>, <a href="https://arxiv.org/abs/2305.14010">question answering</a>, <a href="https://arxiv.org/abs/2403.12242">education</a>, and <a href="https://www.nature.com/articles/s41599-020-0513-5">mental health</a>. My recent projects focus on <a style="color:brown" href="https://link.springer.com/book/10.1007/978-981-97-0747-8">knowledge-augmented NLP</a>, <a style="color:brown" href="https://arxiv.org/abs/2310.13127">instructed LLM</a>, <a style="color:brown" href="https://arxiv.org/abs/2405.14092">self-correct LLM</a>, <a style="color:brown" href="https://arxiv.org/abs/2402.04401">personalized LLM</a>, <a style="color:brown" href="https://arxiv.org/abs/2402.10058">unlearned LLM</a>, <a style="color:purple" href="https://dl.acm.org/doi/abs/10.1145/3534678.3539347">graph data augmentation</a>, and <a style="color:purple" href="https://arxiv.org/abs/2303.10108">graph diffusion model</a>.</p>

    <p>I am directing the <a href="lab.html">Data Mining towards Decision Making (DM2) Lab</a>, supported by National Science Foundation (NSF), National Institutes of Health (NIH), and Office of Naval Research (ONR).</p>

    <p><b>[HIRING #1]</b> The <a href="lab.html">DM2 Lab</a> at <a href="http://cse.nd.edu/">Notre Dame CSE</a> is recruiting two PhD students and one postdoc to begin in <b>Summer/Fall 2026</b>. The research focuses on <i style="color:green">Machine Unlearning</i>, <i style="color:green">Physical AI Safety</i>, and <i style="color:green">AI Ethics</i>. To apply, please visit this <a href="https://engineering.nd.edu/departments-programs/graduate-programs/phd-in-computer-science-and-engineering/">link</a>. Feel free to reach out to me (mjiang2 [at] nd.edu) if you are interested!</p>

    <p>I am also directing the <a href="https://lucyinstitute.nd.edu/centers-and-labs/foundation-models-and-applications-lab-fmal/">Foundation Models and Applications Lab (FAML)</a> at <a href="https://lucyinstitute.nd.edu/">Lucy Institute</a>. By harnessing cutting-edge foundation models, AI systems can rapidly adapt to diverse tasks, from accelerating <b>material discovery</b> to transforming education and healthcare into a more engaging, personalized experience.</p>
    <ul>    
    <table>      
    <td width="570" height="50">
      <li class="O">Tool for molecular discovery: <a href="https://github.com/liugangcode/torch-molecule">torch-molecule</a> is a package that facilitates molecular discovery through deep learning, featuring a user-friendly, sklearn-style interface. It includes model checkpoints for efficient deployment and benchmarking across a range of molecular tasks, including predictive models, generative models, and representation models.
      </li>
    </td>
    <td width="150" height="80">
        <img src="images/package-liu.jpg" width="150" />
    </td>
    </table>
    <table>      
    <td width="550" height="50">
      <li class="O"><a href="https://pubs.acs.org/doi/book/10.1021/acsinfocus.7e9014">Modeling Polymers with Neural Networks</a> is for polymer scientists that are interested in applying machine learning and neural networks. It is designed for college students and published by American Chemical Society in July 2025.
      </li>
      <li class="O"><a href="https://link.springer.com/book/10.1007/978-3-031-84732-5">Deep Learning for Polymer Discovery: Foundation and Advances</a> is for scientists that are interested in advanceing deep learning and data science for polymer informatics. It is designed for graduate-level research and published by Springer in June 2025. (<a href="https://play.google.com/store/books/details/Eric_Inae_Modeling_Polymers_with_Neural_Networks?id=u15zEQAAQBAJ">eBook</a> on Google Play)  
      </li>
    </td>
    <td width="80" height="80">
        <img src="images/cover-inae.jpg" width="80" />
    </td>
    <td width="80" height="80">    
        <img src="images/cover-liu.jpg" width="80" />
    </td>
    </table>
    </ul>
    
    <p><b>[HIRING #2]</b> The <a href="https://lucyinstitute.nd.edu/centers-and-labs/foundation-models-and-applications-lab-fmal/">FAML Lab</a> at <a href="https://lucyinstitute.nd.edu">Lucy Family Institute</a> will be looking for one postdoctoral research associate to begin in <b>Summer/Fall 2026</b> and be co-advised by me and Prof. <a href="https://engineering.nd.edu/faculty/xiangliang-zhang/">Xiangliang Zhang</a>. The research topic is <i style="color:green">Foundation Models and Applications</i>, emphasizing interdisciplinary collaborations. To apply, please visit this <a href="https://lucyinstitute.nd.edu/about-the-lucy-institute/open-positions/">link</a>. Drop me an e-mail (mjiang2 [at] nd.edu) if you are interested!</p>

    <h1>What's New</h1>
    <ul>
    <li class="O">January 2026: Scientific AI <a href="https://sai.nd.edu/programs/sai-winter-schools/">Winter School</a> at the University of Puerto Rico was successful! We presented learning and reasoning for molecular inverse design.</li>    
    <li class="O">December 2025: Welcome <a href="https://vickyli99.github.io/">Weijiang (Vicky) Li</a> to join our lab and the CSE PhD Program in January 2026! <a href="https://liugangcode.github.io/">Gang Liu</a>, with great work on <i>AI for Science</i>, is on the academic job market!</li>
    <li class="O">October 2025: <a href="https://scholar.google.com.pr/citations?user=9d9qJt8AAAAJ">Mengxia</a>'s work on <a href="https://arxiv.org/abs/2504.19406">video-based educational question generation</a> was accepted to <a href="https://eaai-conf.github.io/year/eaai-26.html">EAAI</a>!</li>
    <li class="O">October 2025: We're proud to announce that <a href="https://coefficientgiving.org/">Coefficient Giving</a> is supporting our work on AI safety - <i style="color:green">Probing-Guided Robust Unlearning</i>!</li>	    
    <li class="O">September 2025: <a href="https://yihan226.github.io/">Yihan</a>'s work that learns <a href="https://arxiv.org/abs/2505.10726">repetition-invariant graph representations</a> was accepted to <a href="https://neurips.cc/">NeurIPS</a>!</li>	    
    <li class="O">August 2025: "LLM Function Calling" (led by <a href="https://hygiadang.com/">Hy Dang</a>) and "Zipf's Law in Tokenization"</a> (led by <a href="https://ndi-sa.nd.edu/index.cfm?FuseAction=Programs.ViewProgramAngular&id=10096">iSURE</a> student Yanjin He) were accepted to <a href="https://2025.emnlp.org/">EMNLP</a>!</li>
    <li class="O">June 2025: <a href="https://ytyz1307zzh.github.io/">Zhihan Zhang</a> and <a href="https://lingbo-t.github.io/">Lingbo Tong</a> have successfully passed their dissertation defense. Congratulations, Dr. Zhang and Dr. Tong!</li>
    <!-- <li class="O">May 2025: <a href="lab.html">DM2</a> students are graduating: <a href="https://ytyz1307zzh.github.io/">Zhihan Zhang</a> will join Amazon Rufus as a scientist in June. <a href="https://lingbo-t.github.io/">Lingbo Tong</a> will join the School of Education in the University of Wisconsin-Madison as an assistant professor in August. <a href="https://qingkaizeng.github.io/">Qingkai Zeng</a> will join the School of Computer Science in Nankai University as an assistant professor in 2026. And,</li> -->
    <!-- <li class="O">May 2025: <a href="https://arxiv.org/abs/2410.01744">Leopard</a> (Text-Rich Multi-Image Vision-Language Model) was accepted to <a href="https://jmlr.org/tmlr/">TMLR</a>!</li> -->
    <!-- <li class="O">May 2025: Eight papers were accepted to <a href="https://2025.aclweb.org/">ACL</a> Main and one paper was accepted to <a href="https://2025.aclweb.org/">ACL</a> Findings!</li> -->
    <!-- <li class="O">April 2025: <a href="https://nlp.nd.edu/msld25/">Midwest Speech and Language Days (MSLD)</a> was very successful -- over 130 registrations, 75 presentations, and 4 keynote speakers!</li> -->
    <!-- <li class="O">April 2025: <a href="https://news.mit.edu/2025/could-llms-help-design-our-next-medicines-and-materials-0409">MIT News</a> covered <a href="https://arxiv.org/abs/2410.04223">Llamole</a> -- <a href="https://liugangcode.github.io/">Gang</a>'s ICLR work on molecular multimodal LLMs!</li> -->
    <!-- <li class="O">March 2025: Three new benchmarks <a href="https://arxiv.org/abs/2410.22108">Multimodal Unlearning</a> (led by <a href="https://zheyuanliu.netlify.app/">Frank</a>), <a href="https://openreview.net/pdf?id=iiCyJJszC4">Instruction-following Hierarchy</a> (led by <a href="https://ytyz1307zzh.github.io/">Zhihan</a>), and <a href="https://arxiv.org/abs/2410.14179">MultiChartQA</a> were accepted to <a href="https://2025.naacl.org/">NAACL</a>!</li> -->
    <!-- <li class="O">February 2025: <a href="https://arxiv.org/abs/2410.04223">MLLM for Molecular Design</a> and <a href="https://arxiv.org/abs/2406.12056">Learning Molecular Representations in a Cell</a> (both led by <a href="https://liugangcode.github.io/">Gang</a>) were accepted to <a href="https://iclr.cc/">ICLR</a>!</li> -->
    <!-- <li class="O">January 2025: <a href="https://liugangcode.github.io/">Gang Liu</a> received the 2024-2025 IBM PhD Fellowship for his work on Foundation Models. Congratulations!</li> -->
    <!-- <li class="O">December 2024: <a href="https://qingkaizeng.github.io/">Qingkai Zeng</a> successfully defended his dissertation <i>Improving Scientific Information Extraction with Text Generation</i>. Congratulations, Dr. Zeng!</li> -->
    <!-- <li class="O">November 2024: <a href="#">Sequential Recommendation</a> (led by <a href="https://liugangcode.github.io/">Gang</a>) was accepted to <a href="https://kdd2025.kdd.org/">KDD 2025</a>!</li> -->
    <!-- <li class="O">November 2024: <a href="https://arxiv.org/abs/2309.04589">Motif-aware Graph Pre-training</a> (led by <a href="https://www.linkedin.com/in/eric-inae-6056b1214/">Eric</a>) was accepted to <a href="https://logconference.org/">LoG</a>!</li> -->
    <!-- <li class="O">September 2024: <a href="https://arxiv.org/abs/2401.13858">Graph Diffusion Transformer (Graph DiT)</a> (led by <a href="https://liugangcode.github.io/">Gang</a>) was accepted to <a href="https://neurips.cc/">NeurIPS</a>!</li> -->	    
    <!-- <li class="O">September 2024: <a href="https://arxiv.org/abs/2402.04401">"Personalized PEFT"</a> and <a href="https://arxiv.org/abs/2406.10471">"Collaborative PEFT"</a> (led by <a href="https://zhaoxuan.info/">Zhaoxuan</a>), <a href="https://arxiv.org/abs/2406.12050">"Reflection Augmentation"</a> (led by <a href="https://ytyz1307zzh.github.io/">Zhihan</a>), <a href="#">"Self-correct LLM"</a> (led by <a href="https://scholar.google.com/citations?user=5tVLNpYAAAAJ">Zhenyu</a>), <a href="https://arxiv.org/abs/2403.12242">"Reference-free QG Evaluation"</a> (led by <a href="#">Bang</a>), and <a href="#">"Complex Instruction-following"</a> (led by <a href="https://ziems.github.io/">Noah</a>) were accepted to <a href="https://2024.emnlp.org/">EMNLP</a>!</li> -->
    <!-- <li class="O">July 2024: <a href="https://arxiv.org/abs/2402.07386">"LLM for Taxonomy Induction"</a> (led by <a href="https://ytyz1307zzh.github.io/">Qingkai</a>) was accepted to <a href="https://cikm2024.org/">CIKM</a>!</li> -->	    
    <!-- <li class="O">June 2024: Awarded credits from the <a href="https://openai.com/form/researcher-access-program/">OpenAI Researcher Access Program</a> for a project led by <a href="https://zheyuanliu.netlify.app/">Frank</a>. Thank you, <a href="https://openai.com/">OpenAI</a>!</li> -->
    <!-- <li class="O">May 2024: <a href="https://arxiv.org/abs/2311.08711">"Cross-Lingual Instruction Tuning"</a> (led by <a href="https://ytyz1307zzh.github.io/">Zhihan</a>) and <a href="https://arxiv.org/abs/2402.10058">"Machine Unlearning for LLM Safety"</a> (led by <a href="https://zheyuanliu.netlify.app/">Frank</a>) were accepted to <a href="https://2024.aclweb.org/">ACL</a>!</li> -->	    
    <!-- <li class="O">March 2024: <a href="https://arxiv.org/abs/2403.12744">"Identify and Ignore Irrelevant Conditions"</a> [<a href="https://wzy6642.github.io/I3C.github.io/">project</a>] and <a href="https://arxiv.org/abs/2402.10670">"VLM for Open-Set Object Navigation"</a> [<a href="https://yxkryptonite.github.io/OpenFMNav/">project</a>] were accepted to <a href="https://2024.naacl.org/">NAACL</a>!</li> -->	    
    <!-- <li class="O">February 2024: We are organizing <a href="https://knowledge-nlp.github.io/acl2024/">the Third Workshop on Knowledge Augmented Methods for NLP (KnowledgeNLP)</a> at <a href="https://2024.aclweb.org/">ACL</a> in Bangkok in August. Please submit your amazing work!</li> -->
    <!-- <li class="O">January 2024: Awarded a <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2332270">CBET grant</a> from <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2332270">NSF</a> to work on AI for (polymer) material discovery! We are excited to continue working with <a href="https://engineering.nd.edu/faculty/tengfei-luo/">Prof. Luo</a> and his <a href="https://monsterlab.nd.edu/">MONSTER</a> lab. Thank you, NSF!</li> -->    
    <!-- <li class="O">December 2023: <a href="https://arxiv.org/abs/2312.06867">"Get an A in Math"</a> [<a href="https://wzy6642.github.io/prp.github.io/">project</a>] was accepted to <a href="https://aaai.org/aaai-conference/">AAAI</a>!</li> -->
    <!-- <li class="O">November 2023: <a href="https://arxiv.org/abs/2305.14010">IfQA</a> (led by <a href="https://wyu97.github.io/">Wenhao</a>) was selected for <b>Outstanding Paper Award</b> in <a href="https://2023.emnlp.org/">EMNLP 2023</a>!</li> -->
    <!-- <li class="O">October 2023: <a href="https://arxiv.org/abs/2310.13127">Auto-Instruct</a> (led by <a href="https://ytyz1307zzh.github.io/">Zhihan</a>), <a href="https://arxiv.org/abs/2305.14457">Comparative Reasoning</a> (led by <a href="https://scholar.google.com.pr/citations?user=9d9qJt8AAAAJ">Mengxia</a>), and <a href="https://arxiv.org/abs/2305.14010">IfQA</a> (led by <a href="https://wyu97.github.io/">Wenhao</a>) were accepted to <a href="https://2023.emnlp.org/">EMNLP</a>!</li> -->
    <!-- <li class="O">September 2023: <a href="https://arxiv.org/abs/2303.10108">Graph DiT</a> (graph diffusion transformer, led by <a href="https://liugangcode.github.io/">Gang</a>) was accepted to <a href="https://nips.cc/">NeurIPS</a>!</li> -->
    </ul>

    <h1>Latest Publications</h1>
    <ul>

      <li class="O"><a href="https://arxiv.org/abs/2510.08744">Graph Diffusion Transformers are In-Context Molecular Designers</a>,
      <i>ICLR</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2509.23362">Dual-Space Smoothness for Robust and Balanced LLM Unlearning</a>,
      <i>ICLR</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2507.19457">GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning</a>,
      <i>ICLR</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2504.19406">Context Selection and Rewriting for Video-based Educational Question Generation</a>,
      <i>EAAI</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2505.10726">Learning Repetition-Invariant Representations for Polymer Informatics</a>,
      <i>NeurIPS</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2507.22543">Pre-trained Models Perform the Best When Token Distributions Follow Zipf's Law</a>,
      <i>EMNLP</i>, 2025.
      </li>
      <li class="O"><a href="#">Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates</a>,
      <i>EMNLP</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.01744">Leopard: A Vision Language Model for Text-Rich Multi-Image Tasks</a>,
      <i>TMLR</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2408.09070">CodeTaxo: Enhancing Taxonomy Expansion with Limited Examples via Code Language Prompts</a>,
      <i>Findings of ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2503.05888">QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2503.15354">Optimizing Decomposition for Optimal Claim Verification</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://aclanthology.org/2025.acl-long.295/">Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://aclanthology.org/2025.acl-long.305/">Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://www.arxiv.org/abs/2506.04463">Aligning Large Language Models with Implicit Preferences from User-Generated Content</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.12934">Enhancing Mathematical Reasoning in LLMs by Stepwise Correction</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2507.07030">UniConv: Unifying Retrieval and Response Generation for Large Language Model in Conversation</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.22108">Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2502.08745">IHEval: Evaluating Language Models on Following the Instruction Hierarchy</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.14179">MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2407.09007">Benchmarking Language Model Creativity: A Case Study on Code Generation</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.04223">Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning</a>,
      <i>ICLR</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2406.12056">Learning Molecular Representation in a Cell</a>,
      <i>ICLR</i>, 2025.
      </li>
    </ul>

    <h1>Advised PhD Dissertations</h1>
    <ul>
      <li class="O"><a href="https://dahengwang0705.github.io/">Daheng Wang</a>: <a href="https://doi.org/10.7274/c534fn13d6m">Learning Complementarity and Dynamics for Contextual Behavior Modeling</a> (2021)</li>
      <li class="O"><a href="http://zhao-tong.com/">Tong Zhao</a>: <a href="https://doi.org/10.7274/w3763488m5f">Learning to Augment Data in Graphs</a> (2022)</li>
      <li class="O"><a href="https://wyu97.github.io/">Wenhao Yu</a>: <a href="https://doi.org/10.7274/4b29b567759">Knowledge Augmented Methods for NLP and Beyond</a> (2023)</li>
      <li class="O"><a href="https://qingkaizeng.github.io/">Qingkai Zeng</a>: <a href="https://doi.org/10.7274/28571045">Improving Scientific Information Extraction with Text Generation</a> (2024)</li>
      <li class="O"><a href="https://ytyz1307zzh.github.io/">Zhihan Zhang</a>: <a href="https://doi.org/10.7274/29465300">Instructing Language Models as Intelligent Assistants</a> (2025)</li>      
      <li class="O"><a href="https://lingbo-t.github.io">Lingbo Tong</a>: <a href="https://doi.org/10.7274/29566124">Nonlinear Structural Equation Modeling with Text Data</a> (2025)</li>
    </ul>

    <!-- <h1>Talks and Abstracts</h1> -->
    <!-- <ul> -->
      <!-- <li class="O"><b>Lessons Learned from Enhancing  Knowledge and Reasoning for (Large) Language Models (2024)</b> -->
      <!-- </li> -->
      <!-- <li class="O"><b>Generative AI for Material Science (2024)</b> -->
      <!-- [<a href="talks/talk_abstract_GenAI4.pdf">abstract</a>] -->
      <!-- </li> -->
      <!-- <li class="O"><b>Research Paradigms on Large Language Model and Personalization (2024)</b> -->
      <!-- [<a href="talks/talk_abstract_PersonalizedLLM_Jiang_ND.pdf">abstract</a>] -->
      <!-- </li> -->
      <!-- <li class="O"><b>Instructing Language Models to Do Reasoning Wisely (2024)</b> -->
      <!-- [<a href="talks/talk_abstract_WiseReasoning_Jiang.pdf">abstract</a>] -->
      <!-- </li> -->
      <!-- <li class="O"><b>Information Diversity Improves NLP Solutions (2024)</b> -->
      <!-- [<a href="talks/talk_abstract_Diversity_Jiang.pdf">abstract</a>] -->
      <!-- </li> -->
      <!-- <li class="O"><b>Effective and Efficient Knowledge-Intensive NLP (2023)</b> -->
      <!-- [<a href="talks/talk_abstract_KAugNLP_Jiang_ND.pdf">abstract</a>]: -->
      <!-- cover <a href="https://arxiv.org/abs/2210.12887">RACo</a> (<i style="color:green">EMNLP 2022</i>), <a href="https://arxiv.org/abs/2209.10063">GenRead</a> (<i style="color:green">ICLR 2023</i>), and <a href="https://arxiv.org/abs/2210.03273">EDMem</a> (<i style="color:green">EMNLP 2022</i>). -->
      <!-- </li> -->
      <!-- <li class="O"><b>Data Augmentation for Graph Regression (2023)</b> -->
      <!-- [<a href="talks/talk_abstract_AugGReg_Jiang_ND.pdf">abstract</a>]: -->
      <!-- cover <a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539347">GREA</a> (<i style="color:green">KDD 2022</i>), <a href="https://arxiv.org/abs/2305.12087">SGIR</a> (<i style="color:green">KDD 2023</i>), and <a href="https://arxiv.org/abs/2303.10108">DCT</a> (<i style="color:green">NeurIPS 2023</i>). -->
      <!-- </li> -->
      <!-- <li class="O"><b>Enhancing Language Generation with Knowledge Graphs (2022)</b> -->
      <!-- [<a href="talks/talk_abstract_KG-NLG_Jiang_ND.pdf">abstract</a>]: -->
      <!-- cover <a href="https://aclanthology.org/2021.naacl-main.58/">FASum</a> (<i style="color:green">NAACL 2021</i>), <a href="https://aclanthology.org/2022.findings-acl.149/">MoKGE</a> (<i style="color:green">ACL 2022</i>), and <a href="https://arxiv.org/abs/2210.03273">EDMem</a> (<i style="color:green">EMNLP 2022</i>). -->
      <!-- </li> -->
      <!-- <li class="O"><b>Novel Methods that Learn to Augment Graph Data (2021)</b> -->
      <!-- [<a href="talks/talk_abstract_GAug_Jiang_ND.pdf">abstract</a>]: -->
      <!-- cover <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17315">GAug</a> (<i style="color:green">AAAI 2021</i>), <a href="https://dl.acm.org/doi/abs/10.1145/3459637.3482313">Eland</a> (<i style="color:green">CIKM 2021</i>), <a href="https://arxiv.org/abs/2106.02172">CFLP</a> (<i style="color:green">ICML 2022</i>), and <a href="https://arxiv.org/abs/2206.02886">GREA</a> (<i style="color:green">KDD 2022</i>). -->
      <!-- </li> -->
      <!-- <li class="O"><b>Structured Knowledge is Still Essential to Understand Sciences (2020)</b> -->
      <!-- [<a href="talks/talk_abstract_ScienceKDD_Jiang_ND.pdf">abstract</a>]: -->
      <!-- cover <a href="https://dl.acm.org/doi/abs/10.1145/3292500.3330942">SciKG</a> (<i style="color:green">KDD 2019</i>), <a href="https://aclanthology.org/D19-1029/">MIMO</a> (<i style="color:green">EMNLP 2019</i>), <a href="https://dl.acm.org/doi/abs/10.1145/3366423.3380174">Tablepedia</a> (<i style="color:green">WWW 2020</i>), <a href="https://dl.acm.org/doi/abs/10.1145/3442381.3450090">TCN</a> (<i style="color:green">WWW 2021</i>), and <a href="https://dl.acm.org/doi/abs/10.1145/3447548.3467308">GenTaxo</a> (<i style="color:green">KDD 2021</i>). -->
      <!-- </li> -->
      <!-- <li class="O"><b>Graph Learning for Behavior Modeling (2020)</b>: -->
      <!-- cover <a href="https://dl.acm.org/doi/abs/10.1145/3292500.3330867">TUBE</a> (<i style="color:green">KDD 2019</i>), <a href="https://ieeexplore.ieee.org/abstract/document/9758834">M2TUBE</a> (<i style="color:green">TNNLS 2022</i>), <a href="https://dl.acm.org/doi/abs/10.1145/3394486.3403308">CalendarGNN</a> (<i style="color:green">KDD 2020</i>), <a href="https://ieeexplore.ieee.org/abstract/document/9472956">CoEvoGNN</a> (<i style="color:green">DLG 2020 Best Paper / TKDE 2021</i>), <a href="https://dl.acm.org/doi/abs/10.1145/3340531.3411979">GAL</a> (<i style="color:green">CIKM 2021</i>), and <a href="https://ieeexplore.ieee.org/abstract/document/9525041">PamFul</a> (<i style="color:green">TNNLS 2021</i>), including user profiling, recommendation, and fraud detection. -->
      <!-- </li> -->
      <!-- </ul> -->

  <br><br><br><br><br>
  <br><br><br><br><br>

    <table>
    <td width="90" height="90">
        <img src="images/nsf.jpg" width="90" />
    </td>
    <td width="130" height="130">
        <img src="images/nimh.jpg" width="130" />
    </td>
    <td width="120" height="120">
        <img src="images/onr.png" width="120" />
    </td>
    <td width="100" height="100">
        <img src="images/cicp.png" width="100" />
    </td>
    <td width="100" height="100">
        <img src="images/analytixin.jpg" width="100" />
    </td>
    </table>

    <table>
    <td width="120" height="120">
        <img src="images/amazon.png" width="120" />
    </td>
    <td width="80" height="80">
        <img src="images/snap.png" width="80" />
    </td>
    <td width="120" height="120">
        <img src="images/condenast.png" width="120" />
    </td>
    <td width="77" height="77">
        <img src="images/ndresearch.png" width="77" />
    </td>
    <td width="60" height="60">
        <img src="images/ndinternational.png" width="60" />
    </td>
    <td width="100" height="100">
        <img src="images/ndengineering.png" width="100" />
    </td>
    </table>

  <br><br>
  <p>Last updated on February 2, 2026.</p>

  </div>
  <!-- END: right column -->

  <div id="footer">
    <!-- you can put something here -->
  </div>

  </div>

