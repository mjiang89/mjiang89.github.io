<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="utf-8" />
  <title>Meng Jiang - University of Notre Dame</title>
  <!-- Favicon -->
  <link rel="shortcut icon" href="images/favicon.gif" />
  <!-- Standard reset, fonts and grids -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="styles/reset-fonts-grids.css">
  <!-- styles for the whole website -->
  <link href="styles/styles.css" rel="stylesheet" type="text/css" />
</head>

<body class="yui-skin-sam" id="yahoo-com">
  <div id="doc" class="yui-t1">
  <div id="hd">
    <div id="header"><a href="https://www.nd.edu/"><img id="nd-logo" src="images/logo_nd.png" alt="CSE@NotreDame" /></a></div>
  </div>

  <!-- START: left column -->
  <div id="left-column">
  <!--#include virtual="left_column.html" -->
  <img id="meng-img" src="images/meng.jpg" alt="Meng Jiang" />
  <div id="graphgardenmainmenu" class="yuimenu">
    <div class="bd">
      <ul class="first-of-type">
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="lab.html"><b>DM2 Lab</b></a></li>
      <br>
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="index.html">Home</a></li>
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="pubs.html">Publications</a></li>
      <li class="yuimenuitem first-of-type"><a class="yuimenuitemlabel" href="activities.html">Activities</a></li>
      <br>
      </ul>
    </div>
  </div>
  <br>
  </div>
  <!-- END: left column -->

  <!-- START: right column -->
  <div id="right-column">

    <div class="call-out-orange"><div style="font-size:36px; padding:13px 0px; font-family:Arial, Helvetica, sans-serif; font-weight:bold;";>Meng Jiang</div></div>

    <p>Hi! I am an Associate Professor and Frank M. Freimann Collegiate Professor of <a href="http://cse.nd.edu/">Computer Science and Engineering</a> at the <a href="https://www.nd.edu/">University of Notre Dame</a>. I'm appointed as a <a href="https://lucyinstitute.nd.edu/people/affiliates/">Lucy Family Institute Fellow</a> as well as the Program Chair of <a href="https://ethics.nd.edu/labs-and-centers/notre-dame-ibm-technology-ethics-lab/">ND-IBM Tech Ethics Lab</a>. I am also an <a href="https://www.amazon.science/scholars">Amazon Scholar</a>. My research fields are AI and Data Science. I'm interested in developing <i style="color:green">Strong, Controllable, Multimodal AI</i> for applications such as Sciences (e.g., <a href="https://github.com/liugangcode/DemoDiff">material discovery</a>, <a href="https://wzy6642.github.io/proco.github.io/">math reasoning</a>) and Engineering (e.g., <a href="https://yuxuank.com/OpenFMNav/">physical systems</a>, <a href="https://zhaoxuan.info/">recommender systems</a>), as well as <a href="https://arxiv.org/abs/2504.19406">education</a> and <a href="https://www.nature.com/articles/s41599-020-0513-5">mental health</a>. Typical approaches are:
    <ul>    
    <td height="50">
      <li class="O">Tuning multimodal AI to gain knowledge and skills, and precisely follow complex instructions;
      </li>
      <li class="O">Generalizing multimodal AI capabilities with multi-objective reinforcement learning;
      </li>
      <li class="O">Controlling multimodal AI to act under moral, ethical, or rational guidelines; 
      </li>
      <li class="O">Adapting multimodal AI efficiently for personalization and challenges tasks like scientific discovery.
      </li>
    </td>
    </ul>

    <p>I am directing the <a href="lab.html">Data Mining towards Decision Making (DM2) Lab</a>. The lab is hiring one PhD student to work on <i style="color:green">Physical AI</i>, <i style="color:green">Multimodal AI</i>, <i style="color:green">AI Safety</i>, and <i style="color:green">AI Controllability</i> to begin in Fall 2026 or Spring 2027. Feel free to reach out to me if you are interested!</p>

    <p>The <a href="https://lucyinstitute.nd.edu/centers-and-labs/foundation-models-and-applications-lab-fmal/">Foundation Models and Applications (FAML) Lab</a> at <a href="https://lucyinstitute.nd.edu">Lucy Family Institute</a> is looking for one postdoc to begin in Fall 2026 or Spring 2017. The research topic emphasizes interdisciplinary collaborations. To apply, please visit this <a href="https://lucyinstitute.nd.edu/about-the-lucy-institute/open-positions/">link</a>. Drop me an e-mail if you are interested!</p>

    <h1>What's New</h1>
    <ul>
    <li class="O">February 2026: Welcome <a href="https://goldymoon.github.io/">Jinduo Guo</a> to join our lab and the CSE PhD Program in Fall 2026!</li>	  
    <li class="O">January 2026: <a href="https://engineering.nd.edu/faculty/james-schmiedeler/">Jim</a> and I are organizing the <a href="https://physical-ai-nd.github.io/">Physical AI Working Group</a> supported by the <a href="https://strategicframework.nd.edu/initiatives/data-ai-computing/">Data, AI, and Computing (DAC) Initiative</a> at the University of Notre Dame. Let us know if you are interested in the group activities!</li>	    
    <li class="O">January 2026: Scientific AI <a href="https://sai.nd.edu/programs/sai-winter-schools/">Winter School</a> at the University of Puerto Rico was successful! We presented the work of learning and reasoning for molecular inverse design.</li>    
    <li class="O">December 2025: Welcome <a href="https://vickyli99.github.io/">Weijiang (Vicky) Li</a> to join our lab and the CSE PhD Program in January 2026! <a href="https://liugangcode.github.io/">Gang Liu</a>, with great work on <i>AI for Science</i>, is on the academic job market!</li>
    <li class="O">October 2025: We're proud to announce that <a href="https://coefficientgiving.org/">Coefficient Giving</a> is supporting our work on AI safety - <i style="color:green">Probing-Guided Robust Unlearning</i>!</li>	    
    <li class="O">June 2025: <a href="https://ytyz1307zzh.github.io/">Zhihan Zhang</a> and <a href="https://lingbo-t.github.io/">Lingbo Tong</a> have successfully passed their dissertation defense. Congratulations, Dr. Zhang and Dr. Tong!</li>
    </ul>

    <h1>Latest Publications</h1>
    <ul>

      <li class="O"><a href="https://arxiv.org/abs/2509.11452">Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting</a>,
      <i>TACL</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2510.08744">Graph Diffusion Transformers are In-Context Molecular Designers</a>,
      <i>ICLR</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2509.23362">Dual-Space Smoothness for Robust and Balanced LLM Unlearning</a>,
      <i>ICLR</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2507.19457">GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning</a>,
      <i>ICLR</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2504.19406">Context Selection and Rewriting for Video-based Educational Question Generation</a>,
      <i>EAAI</i>, 2026.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2505.10726">Learning Repetition-Invariant Representations for Polymer Informatics</a>,
      <i>NeurIPS</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2507.22543">Pre-trained Models Perform the Best When Token Distributions Follow Zipf's Law</a>,
      <i>EMNLP</i>, 2025.
      </li>
      <li class="O"><a href="#">Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates</a>,
      <i>EMNLP</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.01744">Leopard: A Vision Language Model for Text-Rich Multi-Image Tasks</a>,
      <i>TMLR</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2408.09070">CodeTaxo: Enhancing Taxonomy Expansion with Limited Examples via Code Language Prompts</a>,
      <i>Findings of ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2503.05888">QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2503.15354">Optimizing Decomposition for Optimal Claim Verification</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://aclanthology.org/2025.acl-long.295/">Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://aclanthology.org/2025.acl-long.305/">Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://www.arxiv.org/abs/2506.04463">Aligning Large Language Models with Implicit Preferences from User-Generated Content</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.12934">Enhancing Mathematical Reasoning in LLMs by Stepwise Correction</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2507.07030">UniConv: Unifying Retrieval and Response Generation for Large Language Model in Conversation</a>,
      <i>ACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.22108">Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2502.08745">IHEval: Evaluating Language Models on Following the Instruction Hierarchy</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.14179">MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2407.09007">Benchmarking Language Model Creativity: A Case Study on Code Generation</a>,
      <i>NAACL</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2410.04223">Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning</a>,
      <i>ICLR</i>, 2025.
      </li>
      <li class="O"><a href="https://arxiv.org/abs/2406.12056">Learning Molecular Representation in a Cell</a>,
      <i>ICLR</i>, 2025.
      </li>
    </ul>

    <h1>Advised PhD Dissertations</h1>
    <ul>
      <li class="O"><a href="https://dahengwang0705.github.io/">Daheng Wang</a>: <a href="https://doi.org/10.7274/c534fn13d6m">Learning Complementarity and Dynamics for Contextual Behavior Modeling</a> (2021)</li>
      <li class="O"><a href="http://zhao-tong.com/">Tong Zhao</a>: <a href="https://doi.org/10.7274/w3763488m5f">Learning to Augment Data in Graphs</a> (2022)</li>
      <li class="O"><a href="https://wyu97.github.io/">Wenhao Yu</a>: <a href="https://doi.org/10.7274/4b29b567759">Knowledge Augmented Methods for NLP and Beyond</a> (2023)</li>
      <li class="O"><a href="https://qingkaizeng.github.io/">Qingkai Zeng</a>: <a href="https://doi.org/10.7274/28571045">Improving Scientific Information Extraction with Text Generation</a> (2024)</li>
      <li class="O"><a href="https://ytyz1307zzh.github.io/">Zhihan Zhang</a>: <a href="https://doi.org/10.7274/29465300">Instructing Language Models as Intelligent Assistants</a> (2025)</li>      
      <li class="O"><a href="https://lingbo-t.github.io">Lingbo Tong</a>: <a href="https://doi.org/10.7274/29566124">Nonlinear Structural Equation Modeling with Text Data</a> (2025)</li>
    </ul>

  <br><br><br><br><br>
  <br><br><br><br><br>

    <table>
    <td width="90" height="90">
        <img src="images/nsf.jpg" width="90" />
    </td>
    <td width="130" height="130">
        <img src="images/nimh.jpg" width="130" />
    </td>
    <td width="120" height="120">
        <img src="images/onr.png" width="120" />
    </td>
    <td width="100" height="100">
        <img src="images/cicp.png" width="100" />
    </td>
    <td width="100" height="100">
        <img src="images/analytixin.jpg" width="100" />
    </td>
    </table>

    <table>
    <td width="120" height="120">
        <img src="images/amazon.png" width="120" />
    </td>
    <td width="80" height="80">
        <img src="images/snap.png" width="80" />
    </td>
    <td width="120" height="120">
        <img src="images/condenast.png" width="120" />
    </td>
    <td width="77" height="77">
        <img src="images/ndresearch.png" width="77" />
    </td>
    <td width="60" height="60">
        <img src="images/ndinternational.png" width="60" />
    </td>
    <td width="100" height="100">
        <img src="images/ndengineering.png" width="100" />
    </td>
    </table>

  <br><br>
  <p>Last updated on February 17, 2026.</p>

  </div>
  <!-- END: right column -->

  <div id="footer">
    <!-- you can put something here -->
  </div>

  </div>

